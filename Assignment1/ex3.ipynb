{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import abc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "# Initialization techniques of weights here defined\n",
    "class WeightInitialization(metaclass=abc.ABCMeta):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def init(self, lower, upper, shape):\n",
    "        pass\n",
    "\n",
    "class UniformDistributionWeight(WeightInitialization):\n",
    "\n",
    "    def init(self, lower, upper, shape):\n",
    "        return np.random.uniform(lower, upper, size=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.83141498,  0.41602419, -0.66019125,  0.25985005,  0.42095398,\n",
       "        0.31099385,  0.93167715,  0.09505453, -0.91957213])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = UniformDistributionWeight().init(-1, 1, 9)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.56884324 -0.87109001  0.7295165  -0.45189619 -0.74623203 -0.43330786\n",
      " -0.2749001  -0.16168629 -0.83897505]\n"
     ]
    }
   ],
   "source": [
    "# constant\n",
    "nodes_per_layer = [2,2,1]\n",
    "bias_value = 1\n",
    "\n",
    "\n",
    "def get_nr_weights(nodes_per_layer):\n",
    "\n",
    "    nr_weights = 0\n",
    "\n",
    "    for idx in range(len(nodes_per_layer) - 1):\n",
    "        current_layer = nodes_per_layer[idx]\n",
    "        next_layer = nodes_per_layer[idx + 1]\n",
    "\n",
    "        nr_weights = nr_weights + (current_layer + 1) * next_layer\n",
    "\n",
    "    return nr_weights\n",
    "\n",
    "\n",
    "weights = UniformDistributionWeight().init(-1, 1, get_nr_weights(nodes_per_layer))\n",
    "print(weights)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.56884324, -0.87109001],\n",
       "        [ 0.7295165 , -0.45189619],\n",
       "        [-0.74623203, -0.43330786]]),\n",
       " array([[-0.2749001 ],\n",
       "        [-0.16168629],\n",
       "        [-0.83897505]])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def divide_in_layers_matrix(weights, nodes_per_layer):\n",
    "\n",
    "    layers = []\n",
    "    last = 0\n",
    "    for idx in range(len(nodes_per_layer) - 1):\n",
    "        \n",
    "        current_layer = nodes_per_layer[idx]\n",
    "        next_layer = nodes_per_layer[idx + 1]\n",
    "        temp = (current_layer + 1) * next_layer\n",
    "        layers.append(weights[last : last + temp].reshape(current_layer + 1, next_layer))\n",
    "        #print(\"{}:{}\".format(last, last + temp))\n",
    "        last = temp\n",
    "\n",
    "    return layers\n",
    "\n",
    "divide_in_layers_matrix(weights, nodes_per_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 1], array([0.21163881, 0.21342579]), array([0.28258753])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def forward_pass(x1, x2 , weights):\n",
    "    input_layer = np.array([x1, x2])\n",
    "    values_output = [[x1, x2, bias_value]]\n",
    "    for idx in range(len(weights)):\n",
    "        weight = weights[idx]\n",
    "        input_layer = np.append(input_layer, [bias_value])\n",
    "        net = np.dot(input_layer, weight)\n",
    "        output = sigmoid(net)\n",
    "        values_output.append(output)\n",
    "        input_layer = output\n",
    "\n",
    "    #values_input.append(input_layer)\n",
    "    return values_output \n",
    "\n",
    "\n",
    "forward_pass(1, 0, divide_in_layers_matrix(weights, nodes_per_layer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.30129068051041197, array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0]]), [[[0, 0, 1], array([0.32164288, 0.39333672]), array([0.27071621])], [[0, 1, 1], array([0.49582122, 0.29210053]), array([0.26453974])], [[1, 0, 1], array([0.21163881, 0.21342579]), array([0.28258753])], [[1, 1, 1], array([0.35765453, 0.14725509]), array([0.27665732])]])\n"
     ]
    }
   ],
   "source": [
    "values_output = []\n",
    "values_input = []\n",
    "\n",
    "def mse(weights):\n",
    "\n",
    "    inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "    expected_output = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "    predicted = []\n",
    "\n",
    "    for possible_inputs in inputs:\n",
    "        val= forward_pass(possible_inputs[0], possible_inputs[1], divide_in_layers_matrix(weights, nodes_per_layer))\n",
    "        predicted.append(val[-1][0])\n",
    "        values_output.append(val)\n",
    "        #print(val)\n",
    "    \n",
    "    predicted = np.array(predicted)\n",
    "\n",
    "    error = expected_output - predicted\n",
    "    error = error * error\n",
    "    #print(error)\n",
    "    return np.mean(error), expected_output , values_output\n",
    "\n",
    "print(mse(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014469027710764188\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7ac23e217c09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mgrdmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-7ac23e217c09>\u001b[0m in \u001b[0;36mgrdmse\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#delta_k = delta_j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mdelta_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayerK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mdelta_j\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0msigmoid_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayerK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdelta_j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayerK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_j\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mlayerK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayerK\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,) (3,) "
     ]
    }
   ],
   "source": [
    "def grdmse(weights):\n",
    "    mse_value, y, outputs =  mse(weights) # returns for the four different inputs\n",
    "    w = divide_in_layers_matrix(weights, nodes_per_layer)\n",
    "\n",
    "\n",
    "\n",
    "    # for the first example\n",
    "    output = outputs[0] # output first layer, output second layer, ..., output last layer\n",
    "    target = y[0]\n",
    "\n",
    "    layerK = len(nodes_per_layer)-1\n",
    "\n",
    "    ######## gradient for the weights between layer n-1 and n #################\n",
    "    delta_j =  (output[layerK] - target) * sigmoid_derivative(output[layerK]) # (y - d) * derivative\n",
    "    print(np.array(output[layerK]).T.dot(delta_j))\n",
    "\n",
    "    layerK = layerK - 1\n",
    "    ############### get other gradient through back propagations ###############\n",
    "    while layerK > 0:\n",
    "        \n",
    "        #delta_k = delta_j\n",
    "        delta_j = np.dot(delta_j, w[layerK].T)\n",
    "        delta_j =  sigmoid_derivative(np.array(output[layerK])) * delta_j\n",
    "        print(np.array(output[layerK]).T.dot(delta_j))\n",
    "        layerK = layerK - 1\n",
    "    \n",
    "    \n",
    "    #print(gradients)\n",
    "\n",
    "\n",
    "\n",
    "grdmse(weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DW for second weights:\n",
      "[[-0.07094707]\n",
      " [-0.04179667]\n",
      " [-0.14309002]]\n",
      "DW for first weights:\n",
      "[[-0. -0. -0.]\n",
      " [-0. -0. -0.]\n",
      " [-0. -0. -0.]]\n"
     ]
    }
   ],
   "source": [
    "def magic(x1, x2 , weights):\n",
    "\n",
    "    input_layer = np.array([x1, x2])\n",
    "    weights =  divide_in_layers_matrix(weights, nodes_per_layer)\n",
    "\n",
    "\n",
    "    inputs = []\n",
    "    \n",
    "    #forward pass\n",
    "    for idx in range(len(weights)):\n",
    "        input_layer = np.append(input_layer, [bias_value])\n",
    "        inputs.append(input_layer)\n",
    "        weight = weights[idx]\n",
    "        net = np.dot(input_layer, weight)\n",
    "        output = sigmoid(net)\n",
    "        input_layer = output # the input of the next layer is the output of the current\n",
    "\n",
    "    inputs = np.array(inputs)\n",
    "    length = len(inputs) - 1\n",
    "\n",
    "    \n",
    "    #backward pass\n",
    "    delta =np.array([np.array(output - (x1 != x2)) * sigmoid_derivative(output)])\n",
    "    print(\"DW for second weights:\")\n",
    "\n",
    "    print(delta * inputs[length].reshape(-1,1))\n",
    "    length -=1\n",
    "\n",
    "    #print(weights[1])\n",
    "    a = sigmoid_derivative(inputs[length]).reshape(1, len(inputs[length]))\n",
    "    some = delta *  weights[1].dot(a) \n",
    "    print(\"DW for first weights:\")\n",
    "    print(np.multiply(some, inputs[0][:, np.newaxis]))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "magic(0,1,weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] [-0.09373024]\n",
      "[0, 1] [0.96915948]\n",
      "[1, 0] [0.9691595]\n",
      "[1, 1] [0.10536446]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return x * (1.0 - x)\n",
    "\n",
    "epochs = 5000\n",
    "input_size, hidden_size, output_size = 2, 2, 1\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Truth table\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# Fill hidden and output layers with random values.\n",
    "w_hidden = np.random.uniform(size=(input_size, hidden_size))\n",
    "w_output = np.random.uniform(size=(hidden_size, output_size))\n",
    "\n",
    "# Learning iteration\n",
    "for epoch in range(epochs):\n",
    "    # Forward propagation\n",
    "    actual_hidden = sigmoid(np.dot(X, w_hidden))\n",
    "    output = np.dot(actual_hidden, w_output)\n",
    "\n",
    "    # Calculate error (expected output - calculated output)\n",
    "    error = Y - output\n",
    "\n",
    "    # Backward Propagation\n",
    "    dZ = error\n",
    "    w_output += learning_rate* actual_hidden.T.dot(dZ)\n",
    "\n",
    "    dH = dZ.dot(w_output.T) * sigmoid_prime(actual_hidden)\n",
    "    w_hidden += X.T.dot(dH)\n",
    "    #print(w_output)\n",
    "    #print(w_hidden)\n",
    "    #print(\"---\")\n",
    "\n",
    "    \n",
    "actual_hidden = sigmoid(np.dot([0, 0], w_hidden))\n",
    "actual_output = np.dot(actual_hidden, w_output)\n",
    "print('[0, 0]', actual_output)\n",
    "\n",
    "actual_hidden = sigmoid(np.dot([0, 1], w_hidden))\n",
    "actual_output = np.dot(actual_hidden, w_output)\n",
    "print('[0, 1]', actual_output)\n",
    "\n",
    "actual_hidden = sigmoid(np.dot([1, 0], w_hidden))\n",
    "actual_output = np.dot(actual_hidden, w_output)\n",
    "print('[1, 0]', actual_output)\n",
    "\n",
    "actual_hidden = sigmoid(np.dot([1, 1], w_hidden))\n",
    "actual_output = np.dot(actual_hidden, w_output)\n",
    "print('[1, 1]', actual_output)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
