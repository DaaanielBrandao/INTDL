{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import abc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "# Initialization techniques of weights here defined\n",
    "class WeightInitialization(metaclass=abc.ABCMeta):\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def init(self, lower, upper, shape):\n",
    "        pass\n",
    "\n",
    "class UniformDistributionWeight(WeightInitialization):\n",
    "\n",
    "    def init(self, lower, upper, shape):\n",
    "        return np.random.uniform(lower, upper, size=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.96805139,  0.58536658,  0.23981411,  0.18636149, -0.69045174,\n",
       "       -0.307527  ,  0.36091206,  0.4239523 ,  0.07894475])"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = UniformDistributionWeight().init(-1, 1, 9)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.4373332   0.06204287  0.41012146 -0.71179974 -0.63281368  0.0892423\n",
      " -0.95646875 -0.17346942 -0.31750509]\n"
     ]
    }
   ],
   "source": [
    "# constant\n",
    "nodes_per_layer = [2,2,1]\n",
    "bias_value = 1\n",
    "\n",
    "\n",
    "def get_nr_weights(nodes_per_layer):\n",
    "\n",
    "    nr_weights = 0\n",
    "\n",
    "    for idx in range(len(nodes_per_layer) - 1):\n",
    "        current_layer = nodes_per_layer[idx]\n",
    "        next_layer = nodes_per_layer[idx + 1]\n",
    "\n",
    "        nr_weights = nr_weights + (current_layer + 1) * next_layer\n",
    "\n",
    "    return nr_weights\n",
    "\n",
    "\n",
    "weights = UniformDistributionWeight().init(-1, 1, get_nr_weights(nodes_per_layer))\n",
    "print(weights)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.4373332 ,  0.06204287],\n",
       "        [ 0.41012146, -0.71179974],\n",
       "        [-0.63281368,  0.0892423 ]]),\n",
       " array([[-0.95646875],\n",
       "        [-0.17346942],\n",
       "        [-0.31750509]])]"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def divide_in_layers_matrix(weights, nodes_per_layer):\n",
    "\n",
    "    layers = []\n",
    "    last = 0\n",
    "    for idx in range(len(nodes_per_layer) - 1):\n",
    "        \n",
    "        current_layer = nodes_per_layer[idx]\n",
    "        next_layer = nodes_per_layer[idx + 1]\n",
    "        temp = (current_layer + 1) * next_layer\n",
    "        layers.append(weights[last : last + temp].reshape(current_layer + 1, next_layer))\n",
    "        #print(\"{}:{}\".format(last, last + temp))\n",
    "        last = temp\n",
    "\n",
    "    return layers\n",
    "\n",
    "divide_in_layers_matrix(weights, nodes_per_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 1], array([0.45128491, 0.53774932]), array([0.30102365])]"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def forward_pass(x1, x2 , weights):\n",
    "    input_layer = np.array([x1, x2])\n",
    "    values_output = [[x1, x2, bias_value]]\n",
    "    for idx in range(len(weights)):\n",
    "        weight = weights[idx]\n",
    "        input_layer = np.append(input_layer, [bias_value])\n",
    "        net = np.dot(input_layer, weight)\n",
    "        output = sigmoid(net)\n",
    "        values_output.append(output)\n",
    "        input_layer = output\n",
    "\n",
    "    #values_input.append(input_layer)\n",
    "    return values_output \n",
    "\n",
    "\n",
    "forward_pass(1, 0, divide_in_layers_matrix(weights, nodes_per_layer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.2881571955798743, array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0]]), [[[0, 0, 1], array([0.34687282, 0.52229578]), array([0.32303029])], [[0, 1, 1], array([0.44455589, 0.34920003]), array([0.30932339])], [[1, 0, 1], array([0.45128491, 0.53774932]), array([0.30102365])], [[1, 1, 1], array([0.55345518, 0.36342841]), array([0.28701797])]])\n"
     ]
    }
   ],
   "source": [
    "values_output = []\n",
    "values_input = []\n",
    "\n",
    "def mse(weights):\n",
    "\n",
    "    inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "    expected_output = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "    predicted = []\n",
    "\n",
    "    for possible_inputs in inputs:\n",
    "        val= forward_pass(possible_inputs[0], possible_inputs[1], divide_in_layers_matrix(weights, nodes_per_layer))\n",
    "        predicted.append(val[-1][0])\n",
    "        values_output.append(val)\n",
    "        #print(val)\n",
    "    \n",
    "    predicted = np.array(predicted)\n",
    "\n",
    "    error = expected_output - predicted\n",
    "    error = error * error\n",
    "    #print(error)\n",
    "    return np.mean(error), expected_output , values_output\n",
    "\n",
    "print(mse(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022819124072430638\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-515-7ac23e217c09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mgrdmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-515-7ac23e217c09>\u001b[0m in \u001b[0;36mgrdmse\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m#delta_k = delta_j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mdelta_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayerK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mdelta_j\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0msigmoid_derivative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayerK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdelta_j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayerK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta_j\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mlayerK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayerK\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,) (3,) "
     ]
    }
   ],
   "source": [
    "def grdmse(weights):\n",
    "    mse_value, y, outputs =  mse(weights) # returns for the four different inputs\n",
    "    w = divide_in_layers_matrix(weights, nodes_per_layer)\n",
    "\n",
    "\n",
    "\n",
    "    # for the first example\n",
    "    output = outputs[0] # output first layer, output second layer, ..., output last layer\n",
    "    target = y[0]\n",
    "\n",
    "    layerK = len(nodes_per_layer)-1\n",
    "\n",
    "    ######## gradient for the weights between layer n-1 and n #################\n",
    "    delta_j =  (output[layerK] - target) * sigmoid_derivative(output[layerK]) # (y - d) * derivative\n",
    "    print(np.array(output[layerK]).T.dot(delta_j))\n",
    "\n",
    "    layerK = layerK - 1\n",
    "    ############### get other gradient through back propagations ###############\n",
    "    while layerK > 0:\n",
    "        \n",
    "        #delta_k = delta_j\n",
    "        delta_j = np.dot(delta_j, w[layerK].T)\n",
    "        delta_j =  sigmoid_derivative(np.array(output[layerK])) * delta_j\n",
    "        print(np.array(output[layerK]).T.dot(delta_j))\n",
    "        layerK = layerK - 1\n",
    "    \n",
    "    \n",
    "    #print(gradients)\n",
    "\n",
    "\n",
    "\n",
    "grdmse(weights)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
